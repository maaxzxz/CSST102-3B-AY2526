# -*- coding: utf-8 -*-
"""End-to-End Machine Learning Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HtzGX_47u-He1eSiNsy5kD41teeGN6kc

# **SOLUTION GUIDE: End-to-End Machine Learning Project (California Housing Dataset)**

**Objective**

To perform a **complete machine learning workflow** — from data exploration to model evaluation — using the ***California Housing dataset.***

# **Step 1: Import Libraries**
"""

# Basic libraries
import pandas as pd # handle numerical operations, data
import numpy as np # handle also numerical
import matplotlib.pyplot as plt # graphs, charts

# ML tools
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error, r2_score

"""# **Step 2: Load the Dataset**"""

housing = fetch_california_housing(as_frame=True)
df = housing.frame

print("Shape:", df.shape)
df.head(10)

"""# **Step 3: Explore and Understand Data**"""

df.info()
df.describe()
df.isnull().sum()

"""# **Step 4: Data Visualization**"""

import seaborn as sns
sns.pairplot(df[['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'MedHouseVal']])
plt.show()

"""# **Step 5: Prepare the Data**"""

X = df.drop('MedHouseVal', axis=1)
y = df['MedHouseVal']

# Split data into 80% training, 20% testing
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Feature scaling
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""# **Step 6: Train Models**

**a. Linear Regression**
"""

lr = LinearRegression()
lr.fit(X_train_scaled, y_train)
y_pred_lr = lr.predict(X_test_scaled)

"""**b. Decision Tree Regressor**"""

tree = DecisionTreeRegressor(max_depth=8, random_state=42)
tree.fit(X_train, y_train)
y_pred_tree = tree.predict(X_test)

"""# **Step 7: Evaluate Models**"""

# Define the function
def evaluate_model(y_true, y_pred, model_name):
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_true, y_pred)
    print(f"{model_name} Performance:")
    print(f"RMSE: {rmse:.4f}")
    print(f"R² Score: {r2:.4f}\n")

# Evaluate Linear Regression
evaluate_model(y_test, y_pred_lr, "Linear Regression")

# Evaluate Decision Tree
evaluate_model(y_test, y_pred_tree, "Decision Tree Regressor")

"""# **Step 8: Visualize Predictions**"""

# Create subplots for side-by-side comparison
plt.figure(figsize=(12, 5))

# Linear Regression plot
plt.subplot(1, 2, 1)
plt.scatter(y_test, y_pred_lr, alpha=0.5, color='royalblue', edgecolor='white')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
plt.title("Linear Regression Predictions vs Actual")
plt.xlabel("Actual Median House Value")
plt.ylabel("Predicted Value")
plt.grid(True)

# Decision Tree plot
plt.subplot(1, 2, 2)
plt.scatter(y_test, y_pred_tree, alpha=0.5, color='teal', edgecolor='white')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
plt.title("Decision Tree Predictions vs Actual")
plt.xlabel("Actual Median House Value")
plt.ylabel("Predicted Value")
plt.grid(True)

plt.tight_layout()
plt.show()

"""# **Optional Enhancement (Feature Importance)**"""

import pandas as pd

importance = tree.feature_importances_
feature_importance = pd.DataFrame({
    'Feature': X.columns,
    'Importance': importance
}).sort_values(by='Importance', ascending=False)

plt.figure(figsize=(8,4))
plt.barh(feature_importance['Feature'], feature_importance['Importance'], color='pink')
plt.title("Decision Tree Feature Importance")
plt.gca().invert_yaxis()
plt.show()